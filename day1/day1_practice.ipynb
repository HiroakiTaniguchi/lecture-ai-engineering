{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# 実践演習 Day 1：streamlitとFastAPIのデモ\n",
        "このノートブックでは以下の内容を学習します。\n",
        "\n",
        "- 必要なライブラリのインストールと環境設定\n",
        "- Hugging Faceからモデルを用いたStreamlitのデモアプリ\n",
        "- FastAPIとngrokを使用したAPIの公開方法\n",
        "\n",
        "演習を始める前に、HuggingFaceとngrokのアカウントを作成し、\n",
        "それぞれのAPIトークンを取得する必要があります。\n",
        "\n",
        "\n",
        "演習の時間では、以下の3つのディレクトリを順に説明します。\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2つ目や3つ目からでも始められる様にノートブックを作成しています。\n",
        "\n",
        "復習の際にもこのノートブックを役立てていただければと思います。\n",
        "\n",
        "### 注意事項\n",
        "「02_streamlit_app」と「03_FastAPI」では、GPUを使用します。\n",
        "\n",
        "これらを実行する際は、Google Colab画面上のメニューから「編集」→ 「ノートブックの設定」\n",
        "\n",
        "「ハードウェアアクセラレーター」の項目の中から、「T4 GPU」を選択してください。\n",
        "\n",
        "このノートブックのデフォルトは「CPU」になっています。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# 環境変数の設定（1~3共有）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubから演習用のコードをCloneします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AIXMavdDEP8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8127b651-fa12-4505-e238-62630afdd257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lecture-ai-engineering'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 79 (delta 28), reused 18 (delta 10), pack-reused 15 (from 2)\u001b[K\n",
            "Receiving objects: 100% (79/79), 64.49 KiB | 528.00 KiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HiroakiTaniguchi/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "必要なAPIトークンを.envに設定します。\n",
        "\n",
        "「lecture-ai-engineering/day1」の配下に、「.env_template」ファイルが存在しています。\n",
        "\n",
        "隠しファイルのため表示されていない場合は、画面左側のある、目のアイコンの「隠しファイルの表示」ボタンを押してください。\n",
        "\n",
        "「.env_template」のファイル名を「.env」に変更します。「.env」ファイルを開くと、以下のような中身になっています。\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ダブルクオーテーションで囲まれた文字列をHuggingfaceのアクセストークンと、ngrokの認証トークンで書き変えてください。\n",
        "\n",
        "それぞれのアカウントが作成済みであれば、以下のURLからそれぞれのトークンを取得できます。\n",
        "\n",
        "- Huggingfaceのアクセストークン\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokの認証トークン\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "書き換えたら、「.env」ファイルをローカルのPCにダウンロードしてください。\n",
        "\n",
        "「01_streamlit_UI」から「02_streamlit_app」へ進む際に、CPUからGPUの利用に切り替えるため、セッションが一度切れてしまいます。\n",
        "\n",
        "その際に、トークンを設定した「.env」ファイルは再作成することになるので、その手間を減らすために「.env」ファイルをダウンロードしておくと良いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "「.env」ファイルを読み込み、環境変数として設定します。次のセルを実行し、最終的に「True」が表示されていればうまく読み込めています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bvEowFfg5lrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "002a72c8-3711-4836-a8ba-767518926d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "/content/lecture-ai-engineering/day1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ディレクトリ「01_streamlit_UI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S28XgOm0ELSM"
      },
      "outputs": [],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYw1q0iXELSN"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "アプリを起動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-E7ucR6ELSN"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "公開URLの後に記載されているURLにブラウザでアクセスすると、streamlitのUIが表示されます。\n",
        "\n",
        "app.pyのコメントアウトされている箇所を編集することで、UIがどの様に変化するか確認してみましょう。\n",
        "\n",
        "streamlitの公式ページには、ギャラリーページがあります。\n",
        "\n",
        "streamlitを使うとpythonという一つの言語であっても、様々なUIを実現できることがわかると思います。\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ディレクトリ「02_streamlit_app」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UeEjlJ7uELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b0e541-b44e-42dd-d21d-072bf8b45251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63XV9wQ-F70",
        "outputId": "1a8d1496-2e1a-4670-c38c-0475d8f71b07"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py            config.py    data.py  metrics.py    requirements.txt\n",
            "chat_feedback.db  database.py  llm.py   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/  ui.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jPxTiEWQELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e508455d-375f-4b6a-bb0f-0b845507e233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `AIE_hirotani` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AIE_hirotani`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitでHuggingfaceのトークン情報を扱うために、streamlit用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ファイルを作成\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# 設定ファイルのディレクトリ確保\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# 設定ファイルを書き込む\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "02_streamlit_appでは、Huggingfaceからモデルをダウンロードするため、初回起動には2分程度時間がかかります。\n",
        "\n",
        "この待ち時間を利用して、app.pyのコードを確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBQyTTWTELSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0906a115-fa68-43b0-d88f-a871e55b1d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://e08d-34-16-178-82.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.178.82:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-28 11:09:00.035985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745838540.292380    3651 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745838540.367918    3651 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 11:09:00.943630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "config.json: 100% 805/805 [00:00<00:00, 4.44MB/s]\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 58.5MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/241M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.99G [00:00<00:34, 142MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 10.5M/241M [00:00<00:04, 55.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.99G [00:00<00:31, 159MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 31.5M/241M [00:00<00:02, 104MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.99G [00:00<00:25, 190MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 52.4M/241M [00:00<00:01, 116MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.99G [00:00<00:28, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.99G [00:00<00:29, 167MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 73.4M/241M [00:00<00:01, 118MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.99G [00:00<00:29, 164MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 94.4M/241M [00:00<00:01, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.99G [00:00<00:28, 170MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 115M/241M [00:00<00:01, 125MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.99G [00:01<00:28, 169MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 136M/241M [00:01<00:00, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.99G [00:01<00:25, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.99G [00:01<00:26, 179MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 157M/241M [00:01<00:00, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.99G [00:01<00:25, 182MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 178M/241M [00:01<00:00, 130MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.99G [00:01<00:25, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.99G [00:01<00:24, 190MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 199M/241M [00:01<00:00, 129MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.99G [00:01<00:25, 185MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 220M/241M [00:01<00:00, 132MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.99G [00:01<00:23, 194MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:01<00:00, 120MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.99G [00:02<00:26, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.99G [00:02<00:23, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.99G [00:02<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.99G [00:02<00:20, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.99G [00:02<00:19, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.99G [00:02<00:19, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.99G [00:02<00:19, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.99G [00:03<00:19, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.99G [00:03<00:20, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.99G [00:03<00:20, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.99G [00:03<00:21, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.99G [00:03<00:21, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.99G [00:03<00:21, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.99G [00:03<00:24, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.99G [00:04<00:22, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.99G [00:04<00:22, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.99G [00:04<00:21, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.99G [00:04<00:20, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 870M/4.99G [00:04<00:21, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.99G [00:04<00:20, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.99G [00:04<00:20, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.99G [00:04<00:18, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.99G [00:05<00:19, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.99G [00:05<00:18, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.99G [00:05<00:19, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.99G [00:05<00:20, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.99G [00:05<00:20, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/4.99G [00:05<00:20, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.99G [00:05<00:19, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.99G [00:06<00:17, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.99G [00:06<00:17, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.99G [00:06<00:18, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/4.99G [00:06<00:18, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.99G [00:06<00:18, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.99G [00:06<00:18, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.99G [00:06<00:18, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.99G [00:06<00:17, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.99G [00:07<00:16, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.99G [00:07<00:16, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.99G [00:07<00:15, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.99G [00:07<00:14, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.52G/4.99G [00:07<00:14, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.99G [00:07<00:13, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.99G [00:07<00:14, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/4.99G [00:07<00:13, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.99G [00:08<00:13, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.99G [00:08<00:13, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.99G [00:08<00:13, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.99G [00:08<00:13, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.99G [00:08<00:12, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.99G [00:08<00:12, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.99G [00:08<00:13, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/4.99G [00:08<00:12, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.99G [00:09<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.99G [00:09<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.99G [00:09<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.99G [00:09<00:12, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.99G [00:09<00:12, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.99G [00:09<00:12, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.99G [00:09<00:12, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/4.99G [00:10<00:12, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.99G [00:10<00:11, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.99G [00:10<00:17, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/4.99G [00:10<00:15, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.99G [00:10<00:13, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.99G [00:10<00:12, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.99G [00:10<00:12, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.99G [00:11<00:12, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.99G [00:11<00:11, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.99G [00:11<00:11, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.99G [00:13<01:10, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.99G [00:14<00:58, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.99G [00:14<00:49, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.99G [00:14<00:41, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.99G [00:14<00:30, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/4.99G [00:14<00:23, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.99G [00:14<00:20, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/4.99G [00:14<00:16, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.99G [00:15<00:14, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.99G [00:15<00:12, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.99G [00:15<00:11, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.99G [00:15<00:11, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.77G/4.99G [00:15<00:10, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.99G [00:15<00:09, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.99G [00:15<00:09, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/4.99G [00:16<00:08, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.99G [00:16<00:08, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.99G [00:16<00:08, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.96G/4.99G [00:16<00:08, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.99G [00:16<00:08, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.99G [00:16<00:08, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.99G [00:16<00:08, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.99G [00:17<00:08, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/4.99G [00:17<00:08, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [00:17<00:08, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.99G [00:17<00:08, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/4.99G [00:17<00:07, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.99G [00:17<00:08, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/4.99G [00:17<00:08, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.99G [00:18<00:08, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [00:18<00:08, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.99G [00:18<00:18, 90.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/4.99G [00:18<00:15, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.99G [00:19<00:13, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/4.99G [00:19<00:10, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.99G [00:19<00:10, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.99G [00:19<00:09, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.99G [00:19<00:09, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.99G [00:19<00:08, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/4.99G [00:19<00:08, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.99G [00:19<00:08, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/4.99G [00:19<00:07, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.99G [00:20<00:07, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.61G/4.99G [00:20<00:07, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.99G [00:20<00:06, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/4.99G [00:20<00:06, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.99G [00:20<00:06, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.99G [00:20<00:05, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/4.99G [00:20<00:05, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.99G [00:21<00:05, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.99G [00:21<00:04, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.99G [00:21<00:04, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.99G [00:21<00:06, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.90G/4.99G [00:21<00:06, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.99G [00:21<00:05, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.96G/4.99G [00:21<00:05, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.99G [00:22<00:04, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.99G [00:23<00:17, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.06G/4.99G [00:23<00:13, 70.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.99G [00:23<00:09, 90.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.99G [00:24<00:07, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/4.99G [00:24<00:06, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.99G [00:24<00:05, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.99G [00:24<00:04, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.99G [00:24<00:03, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.99G [00:24<00:03, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.31G/4.99G [00:24<00:03, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.99G [00:24<00:03, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.99G [00:25<00:02, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.40G/4.99G [00:25<00:02, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.99G [00:25<00:02, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.99G [00:25<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/4.99G [00:25<00:02, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.99G [00:25<00:01, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/4.99G [00:25<00:01, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.99G [00:26<00:01, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.99G [00:26<00:01, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/4.99G [00:26<00:01, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.99G [00:26<00:01, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.99G [00:26<00:01, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/4.99G [00:26<00:00, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.99G [00:26<00:00, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/4.99G [00:26<00:00, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/4.99G [00:27<00:00, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.99G [00:27<00:00, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/4.99G [00:27<00:00, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.99G [00:27<00:00, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:27<00:00, 180MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:27<00:00, 13.90s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  9.49it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 971kB/s]\n",
            "tokenizer_config.json: 100% 46.9k/46.9k [00:00<00:00, 32.7MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 50.9MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 218MB/s]\n",
            "special_tokens_map.json: 100% 555/555 [00:00<00:00, 3.41MB/s]\n",
            "Device set to use cpu\n",
            "2025-04-28 11:09:45.793 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46B_EsVuim50"
      },
      "source": [
        "アプリケーションの機能としては、チャット機能や履歴閲覧があります。\n",
        "\n",
        "これらの機能を実現するためには、StreamlitによるUI部分だけではなく、SQLiteを使用したチャット履歴の保存やLLMのモデルを呼び出した推論などの処理を組み合わせることで実現しています。\n",
        "\n",
        "- **`app.py`**: アプリケーションのエントリーポイント。チャット機能、履歴閲覧、サンプルデータ管理のUIを提供します。\n",
        "- **`ui.py`**: チャットページや履歴閲覧ページなど、アプリケーションのUIロジックを管理します。\n",
        "- **`llm.py`**: LLMモデルのロードとテキスト生成を行うモジュール。\n",
        "- **`database.py`**: SQLiteデータベースを使用してチャット履歴やフィードバックを保存・管理します。\n",
        "- **`metrics.py`**: BLEUスコアやコサイン類似度など、回答の評価指標を計算するモジュール。\n",
        "- **`data.py`**: サンプルデータの作成やデータベースの初期化を行うモジュール。\n",
        "- **`config.py`**: アプリケーションの設定（モデル名やデータベースファイル名）を管理します。\n",
        "- **`requirements.txt`**: このアプリケーションを実行するために必要なPythonパッケージ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ディレクトリ「03_FastAPI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ejjDLxr3kfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d96626f3-9980-43c8-be7c-5ced76c646cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ELzWhMFORRIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19ad7da-dc98-4ddd-8f94-46b3ac3c3e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `AIE_hirotani` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AIE_hirotani`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "「02_streamlit_app」から続けて「03_FastAPI」を実行している場合は、モデルのダウンロードが済んでいるため、すぐにサービスが立ち上がります。\n",
        "\n",
        "「03_FastAPI」のみを実行している場合は、初回の起動時にモデルのダウンロードが始まるので、モデルのダウンロードが終わるまで数分間待ちましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "meQ4SwISn3IQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3007546c-7f6b-4e78-b54d-4cb053d2ed3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-28 09:30:59.500544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745832659.692815    2257 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745832659.744769    2257 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-28 09:31:00.171650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "モデル名を設定: google/gemma-2-2b-jpn-it\n",
            "/content/lecture-ai-engineering/day1/03_FastAPI/app.py:134: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "FastAPIエンドポイントを定義しました。\n",
            "アクティブなngrokトンネルはありません。\n",
            "ポート8501に新しいngrokトンネルを開いています...\n",
            "---------------------------------------------------------------------\n",
            "✅ 公開URL:   https://ced8-34-106-172-21.ngrok-free.app\n",
            "📖 APIドキュメント (Swagger UI): https://ced8-34-106-172-21.ngrok-free.app/docs\n",
            "---------------------------------------------------------------------\n",
            "(APIクライアントやブラウザからアクセスするためにこのURLをコピーしてください)\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m2257\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "load_model_task: モデルの読み込みを開始...\n",
            "使用デバイス: cpu\n",
            "config.json: 100% 805/805 [00:00<00:00, 4.33MB/s]\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 65.5MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/241M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.99G [00:00<00:53, 93.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 10.5M/241M [00:00<00:03, 64.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.99G [00:00<00:33, 148MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 21.0M/241M [00:00<00:02, 81.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.99G [00:00<00:29, 167MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 41.9M/241M [00:00<00:01, 110MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.99G [00:00<00:27, 177MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 62.9M/241M [00:00<00:01, 116MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.99G [00:00<00:31, 156MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.99G [00:00<00:29, 164MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 83.9M/241M [00:00<00:01, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.99G [00:00<00:28, 170MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 105M/241M [00:00<00:01, 131MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.99G [00:01<00:28, 167MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 126M/241M [00:01<00:00, 141MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.99G [00:01<00:28, 171MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 147M/241M [00:01<00:00, 157MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.99G [00:01<00:27, 176MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 168M/241M [00:01<00:00, 158MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.99G [00:01<00:28, 167MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 189M/241M [00:01<00:00, 154MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.99G [00:02<02:00, 39.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 210M/241M [00:03<00:00, 35.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.99G [00:03<01:38, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.99G [00:03<01:17, 60.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:03<00:00, 73.1MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.99G [00:03<01:05, 71.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.99G [00:03<00:55, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.99G [00:03<00:46, 99.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.99G [00:03<00:40, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.99G [00:03<00:36, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.99G [00:04<00:32, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.99G [00:04<00:29, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 472M/4.99G [00:04<00:27, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.99G [00:04<00:26, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.99G [00:04<00:23, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.99G [00:04<00:22, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.99G [00:04<00:21, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.99G [00:04<00:21, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.99G [00:05<00:21, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.99G [00:05<00:20, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.99G [00:05<00:20, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.99G [00:05<00:19, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.99G [00:05<00:19, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.99G [00:05<00:19, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.99G [00:05<00:18, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.99G [00:06<00:18, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.99G [00:06<00:17, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/4.99G [00:06<00:17, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.99G [00:06<00:17, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.99G [00:06<00:16, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.99G [00:06<00:16, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.99G [00:06<00:17, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.99G [00:07<00:18, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.99G [00:07<00:18, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.99G [00:07<00:17, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.99G [00:07<00:34, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.99G [00:08<00:29, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.99G [00:08<00:25, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/4.99G [00:08<00:23, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.99G [00:08<00:21, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.99G [00:08<00:19, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.99G [00:08<00:19, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.99G [00:08<00:18, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/4.99G [00:09<00:17, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.99G [00:09<00:17, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.99G [00:09<00:17, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.99G [00:09<00:16, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.99G [00:09<00:16, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.99G [00:09<00:16, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.99G [00:09<00:16, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.99G [00:10<00:15, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/4.99G [00:10<00:22, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.99G [00:10<00:19, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.99G [00:10<00:17, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.99G [00:10<00:16, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.99G [00:11<00:16, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/4.99G [00:11<00:15, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.99G [00:11<00:14, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.99G [00:11<00:14, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.99G [00:11<00:14, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.99G [00:11<00:14, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.99G [00:11<00:14, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.99G [00:12<00:13, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [00:12<00:13, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/4.99G [00:12<00:13, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.99G [00:12<00:13, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.99G [00:12<00:13, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.99G [00:12<00:13, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.99G [00:12<00:12, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.99G [00:13<00:12, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.99G [00:13<00:12, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.99G [00:13<00:12, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/4.99G [00:13<00:12, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.99G [00:13<00:12, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.99G [00:13<00:11, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.99G [00:13<00:11, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.99G [00:14<00:11, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.99G [00:14<00:11, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.99G [00:14<00:11, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.99G [00:14<00:11, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.99G [00:14<00:11, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.99G [00:14<00:10, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.99G [00:14<00:11, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/4.99G [00:15<00:11, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.99G [00:15<00:11, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.99G [00:15<00:11, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.99G [00:15<00:10, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.77G/4.99G [00:18<01:21, 27.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.99G [00:18<00:57, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.99G [00:18<00:42, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/4.99G [00:19<00:31, 67.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.99G [00:19<00:26, 78.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.99G [00:19<00:22, 92.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.99G [00:19<00:17, 115MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/4.99G [00:19<00:14, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.99G [00:19<00:13, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.99G [00:19<00:11, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.99G [00:19<00:10, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.99G [00:20<00:09, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/4.99G [00:20<00:09, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [00:20<00:08, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.99G [00:20<00:08, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/4.99G [00:20<00:08, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.99G [00:20<00:07, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.99G [00:21<00:11, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.99G [00:21<00:10, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [00:24<01:15, 22.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.99G [00:24<00:50, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.99G [00:25<00:35, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/4.99G [00:25<00:25, 61.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.99G [00:25<00:21, 72.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.46G/4.99G [00:25<00:16, 92.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.99G [00:25<00:14, 105MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/4.99G [00:25<00:11, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.99G [00:25<00:10, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/4.99G [00:25<00:08, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.99G [00:26<00:07, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.99G [00:26<00:07, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/4.99G [00:26<00:06, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.99G [00:26<00:06, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.99G [00:26<00:06, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/4.99G [00:26<00:05, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.99G [00:26<00:05, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.99G [00:27<00:05, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.99G [00:27<00:05, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.99G [00:27<00:05, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.91G/4.99G [00:28<00:19, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.99G [00:31<00:38, 27.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/4.99G [00:31<00:30, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.99G [00:31<00:20, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.99G [00:31<00:14, 65.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/4.99G [00:31<00:11, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.99G [00:31<00:09, 96.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/4.99G [00:31<00:07, 118MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.99G [00:31<00:06, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/4.99G [00:32<00:05, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.99G [00:32<00:04, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/4.99G [00:33<00:17, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.99G [00:33<00:13, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.26G/4.99G [00:34<00:09, 75.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.99G [00:34<00:07, 98.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.99G [00:34<00:05, 120MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.99G [00:34<00:04, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.99G [00:34<00:03, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.40G/4.99G [00:34<00:03, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.99G [00:34<00:02, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.99G [00:34<00:02, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/4.99G [00:35<00:02, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.99G [00:35<00:02, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/4.99G [00:35<00:01, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.99G [00:35<00:01, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.99G [00:35<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/4.99G [00:35<00:01, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.99G [00:35<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.99G [00:36<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/4.99G [00:36<00:01, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.99G [00:36<00:00, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/4.99G [00:36<00:00, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/4.99G [00:36<00:00, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.99G [00:36<00:00, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/4.99G [00:36<00:00, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.99G [00:37<00:00, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [00:37<00:00, 133MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:37<00:00, 18.83s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00, 12.44it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.13MB/s]\n",
            "tokenizer_config.json: 100% 46.9k/46.9k [00:00<00:00, 3.79MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 43.5MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 132MB/s]\n",
            "special_tokens_map.json: 100% 555/555 [00:00<00:00, 2.95MB/s]\n",
            "Device set to use cpu\n",
            "モデル 'google/gemma-2-2b-jpn-it' の読み込みに成功しました\n",
            "load_model_task: モデルの読み込みが完了しました。\n",
            "起動時にモデルの初期化が完了しました。\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8501\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.5.140.178:0 - \"\u001b[1mGET /health HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "シンプルなリクエストを受信: prompt=string..., max_new_tokens=512\n",
            "モデル推論を開始...\n",
            "t=2025-04-28T09:44:11+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-b9541f31-3043-4423-acc8-6737fd20baee acceptErr=\"failed to accept connection: Listener closed\"\n",
            "t=2025-04-28T09:44:11+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-b9541f31-3043-4423-acc8-6737fd20baee err=\"failed to start tunnel: session closed\"\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIが起動すると、APIとクライアントが通信するためのURL（エンドポイント）が作られます。\n",
        "\n",
        "URLが作られるのと合わせて、Swagger UIというWebインターフェースが作られます。\n",
        "\n",
        "Swagger UIにアクセスすることで、APIの仕様を確認できたり、APIをテストすることができます。\n",
        "\n",
        "Swagger UIを利用することで、APIを通してLLMを動かしてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}